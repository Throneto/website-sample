# robots.txt for 171780.xyz
# This file tells search engines which pages or files they can or can't request from your site.
# Learn more: https://www.robotstxt.org/

# Allow all search engines to crawl all public content (default behavior)
User-agent: *
Allow: /

# Disallow sensitive areas and backend administration
Disallow: /pages/admin.html
Disallow: /tools/
Disallow: /data/
Disallow: /includes/

# Disallow configuration and system files
Disallow: /*.env$
Disallow: /.git/
Disallow: /package.json
Disallow: /vercel.json
Disallow: /Dockerfile
Disallow: /*.conf$
Disallow: /.github/

# Sitemap location for all crawlers
Sitemap: https://171780.xyz/sitemap.xml

# Specific rules for major search engines

# Google Googlebot
User-agent: Googlebot
Allow: /
Crawl-delay: 0

# Google Image Search
User-agent: Googlebot-Image
Allow: /

# Google Mobile
User-agent: Googlebot-Mobile
Allow: /

# Bing
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Yandex
User-agent: Yandex
Allow: /
Crawl-delay: 1

# DuckDuckGo
User-agent: DuckDuckBot
Allow: /

# Note: Crawl-delay helps prevent server overload
# A delay of 1 second between requests is reasonable for most sites
